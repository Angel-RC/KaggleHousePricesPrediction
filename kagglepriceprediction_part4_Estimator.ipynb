{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "kagglepriceprediction_part4_Estimator.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNVygEXXkMl5CC+yclWKh07",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jhwang1992/KaggleHousePricesPrediction/blob/master/kagglepriceprediction_part4_Estimator.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3vsQS1pb7WWN",
        "colab_type": "text"
      },
      "source": [
        "# update to TensorFlow 2.0"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9d8xoQ0H7Vkr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# update to tensorflow 2.0\n",
        "\n",
        "!pip install --upgrade tensorflow-gpu"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Do77jW8C7f5m",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "0e2f665a-1f6d-47bc-f7d4-a27e026ab766"
      },
      "source": [
        "# check whether the update is successful\n",
        "\n",
        "from __future__ import absolute_import, division, print_function, unicode_literals\n",
        "\n",
        "try:\n",
        "  import tensorflow.compat.v2 as tf\n",
        "except Exception:\n",
        "  pass\n",
        "\n",
        "tf.enable_v2_behavior()\n",
        "\n",
        "print(tf.__version__)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2.1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vh5bPF9Q7hw0",
        "colab_type": "text"
      },
      "source": [
        "# pickle load data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "grrTWnoq6fKM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6bkJo-II6uXV",
        "colab_type": "code",
        "outputId": "db606344-e947-4339-dff8-7f8f47ac0d21",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import seaborn as sns\n",
        "\n",
        "import pickle\n",
        "\n",
        "import warnings as wrn\n",
        "wrn.filterwarnings('ignore', category = DeprecationWarning) \n",
        "wrn.filterwarnings('ignore', category = FutureWarning) \n",
        "wrn.filterwarnings('ignore', category = UserWarning)\n",
        "\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.model_selection import GridSearchCV, train_test_split\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder, LabelEncoder\n",
        "from sklearn.metrics import make_scorer, mean_squared_error\n",
        "\n",
        "import tensorflow as tf\n",
        "import tensorflow_datasets as tfds\n",
        "from tensorflow import feature_column\n",
        "from tensorflow.keras import layers\n",
        "from keras.utils.vis_utils import plot_model\n",
        "from tensorflow import keras"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y2P-iYJd6uLu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with open('df_train.pkl', 'rb') as f:\n",
        "    df_train = pickle.load(f)\n",
        "\n",
        "with open('df_test.pkl', 'rb') as f:\n",
        "    df_test = pickle.load(f)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uq2RnQcnSrwR",
        "colab_type": "code",
        "outputId": "f309f2b2-1349-4745-9a85-89a9b61a41db",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "print('df_train shape: ', df_train.shape)\n",
        "print('df_test shape: ', df_test.shape)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "df_train shape:  (1450, 76)\n",
            "df_test shape:  (1459, 75)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FUuSugVF1FYv",
        "colab_type": "text"
      },
      "source": [
        "# identify numeric and categorical columns"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lf1l4oTXSuMe",
        "colab_type": "code",
        "outputId": "cc8b0ddd-3754-433c-9fac-0fd097e94964",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        }
      },
      "source": [
        "numericColumns = []\n",
        "categoricalColumns = []\n",
        "\n",
        "for column in df_train.columns:\n",
        "  if df_train[column].dtypes==int or df_train[column].dtypes==float:\n",
        "    numericColumns.append(column)\n",
        "  else:\n",
        "    categoricalColumns.append(column)\n",
        "\n",
        "numericColumns.remove('Id')\n",
        "numericColumns.remove('SalePrice')\n",
        "\n",
        "print( len(numericColumns), 'numeric columns: ', numericColumns)\n",
        "print( len(categoricalColumns), 'categorical columns: ', categoricalColumns)\n",
        "print( 'ID and SalePrice are seperated')"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "54 numeric columns:  ['MSSubClass', 'LotFrontage', 'LotArea', 'LotShape', 'LandContour', 'Utilities', 'LandSlope', 'OverallQual', 'OverallCond', 'YearBuilt', 'YearRemodAdd', 'MasVnrArea', 'ExterQual', 'ExterCond', 'BsmtQual', 'BsmtExposure', 'BsmtFinType1', 'BsmtFinSF1', 'BsmtFinType2', 'BsmtFinSF2', 'BsmtUnfSF', 'TotalBsmtSF', 'HeatingQC', 'Electrical', '1stFlrSF', '2ndFlrSF', 'LowQualFinSF', 'GrLivArea', 'BsmtFullBath', 'BsmtHalfBath', 'FullBath', 'HalfBath', 'BedroomAbvGr', 'KitchenAbvGr', 'KitchenQual', 'TotRmsAbvGrd', 'Functional', 'Fireplaces', 'GarageYrBlt', 'GarageFinish', 'GarageCars', 'GarageArea', 'GarageQual', 'GarageCond', 'PavedDrive', 'WoodDeckSF', 'OpenPorchSF', 'EnclosedPorch', '3SsnPorch', 'ScreenPorch', 'PoolArea', 'MiscVal', 'MoSold', 'YrSold']\n",
            "20 categorical columns:  ['MSZoning', 'Street', 'LotConfig', 'Neighborhood', 'Condition1', 'Condition2', 'BldgType', 'HouseStyle', 'RoofStyle', 'RoofMatl', 'Exterior1st', 'Exterior2nd', 'MasVnrType', 'Foundation', 'BsmtCond', 'Heating', 'CentralAir', 'GarageType', 'SaleType', 'SaleCondition']\n",
            "ID and SalePrice are seperated\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FgEvyjAy1NKv",
        "colab_type": "text"
      },
      "source": [
        "# data preprocessing using pandas dataframe and scikit-learn\n",
        "\n",
        "1. impute numeric and categorical columns\n",
        "\n",
        "2. labelencode string categorical columns\n",
        "\n",
        "3. split the data into train, validation\n",
        "\n",
        "4. standardscale the input datasets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z8PnP6ZTedOI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# categorical columns fillna\n",
        "# firstly, to avoid loss nan during NN training\n",
        "# secondly, to be able to pass to labelencoder\n",
        "\n",
        "for column in categoricalColumns:\n",
        "  df_train[column].fillna('missing', inplace = True)\n",
        "  df_test[column].fillna('missing', inplace = True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eWYcN0W9dIdU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# labelencode string categorical column to integer categorical column\n",
        "# tf.dataset cannot take in mixed data type, and thus need to change to numeric\n",
        "# take care of df_test labelencoder transform, there are unique labels not in df_train\n",
        "\n",
        "import bisect\n",
        "\n",
        "for column in categoricalColumns:\n",
        "  le = LabelEncoder()\n",
        "  le.fit(df_train[column])\n",
        "  df_train[column] = le.transform(df_train[column])\n",
        "  le_classes = le.classes_.tolist()\n",
        "  \n",
        "  # to handle categorical feature only in testing data\n",
        "  # handle int and string categorical columns differently\n",
        "  if type(le_classes[0]) is str:\n",
        "    df_test[column] = df_test[column].map(lambda s: 'other' if s not in le.classes_ else s)\n",
        "    bisect.insort_left(le_classes, 'other')\n",
        "    le.classes_ = le_classes\n",
        "    df_test[column] = le.transform(df_test[column])\n",
        "  else:\n",
        "    df_test[column] = df_test[column].map(lambda s: -1 if s not in le.classes_ else s)\n",
        "    bisect.insort_left(le_classes, -1)\n",
        "    le.classes_ = le_classes\n",
        "    df_test[column] = le.transform(df_test[column])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tRKOGuV4WsnY",
        "colab_type": "code",
        "outputId": "96f72252-01dd-45ef-be50-221ff063323d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        }
      },
      "source": [
        "# split data into train/validation/testing pandas dataframes\n",
        "# validation dataframe is to be passed into fit()\n",
        "\n",
        "df_train, df_validation = train_test_split(df_train, test_size=0.2)\n",
        "print(len(df_train), 'train examples')\n",
        "print(len(df_validation), 'validation examples')\n",
        "df_test.SalePrice = 0\n",
        "print(len(df_test), 'test examples')"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1160 train examples\n",
            "290 validation examples\n",
            "1459 test examples\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uu8RS9g4Q8c5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# numeric columns fillna, to avoid loss nan during NN training\n",
        "\n",
        "for column in numericColumns:\n",
        "  df_train[column].fillna(df_train[column].median(), inplace = True)\n",
        "  df_validation[column].fillna(df_train[column].median(), inplace = True)\n",
        "  df_test[column].fillna(df_test[column].median(), inplace = True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hK9A_8m__tau",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# standardscale the input data\n",
        "\n",
        "scaler = StandardScaler()\n",
        "df_train[numericColumns] = scaler.fit_transform(df_train[numericColumns])\n",
        "df_validation[numericColumns] = scaler.transform(df_validation[numericColumns])\n",
        "df_test[numericColumns] = scaler.transform(df_test[numericColumns])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1oMHENzifYh_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_test['SalePrice'] = 0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cFtfZZeTXp4P",
        "colab_type": "text"
      },
      "source": [
        "# step 1: build input_fn"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZGmNyqR0XhaS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# function to build tf.dataset from pandas dataframes\n",
        "# three seperate tensorflow.dataset need to be built for train,validation,and testing\n",
        "# tf.dataset has repeat(equivalent to epoch) and batch_size\n",
        "# steps = repeat * (total sample number/batch_size)\n",
        "\n",
        "def input_fn(dataframe, shuffle=True, batch_size=32):\n",
        "  dataframe = dataframe.copy()\n",
        "  labels = dataframe.pop('SalePrice')\n",
        "  ds = tf.data.Dataset.from_tensor_slices((dict(dataframe), labels))\n",
        "  if shuffle:\n",
        "    ds = ds.shuffle(buffer_size=len(dataframe))\n",
        "  ds = ds.batch(batch_size)\n",
        "  return ds"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xy02de2AgKVO",
        "colab_type": "text"
      },
      "source": [
        "# step 2: define feature_column"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bfey9HwzXw5k",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "feature_columns = []\n",
        "\n",
        "for col in numericColumns:\n",
        "  col = feature_column.numeric_column(col)\n",
        "  feature_columns.append(col)\n",
        "\n",
        "for col in categoricalColumns:\n",
        "  col = feature_column.indicator_column(feature_column.categorical_column_with_vocabulary_list(col,df_train[col].unique()))\n",
        "  feature_columns.append(col)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ydiV6nkyl09e",
        "colab_type": "text"
      },
      "source": [
        "# step 3: initiate prebuild estimator"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uVl0xu4pYK_w",
        "colab_type": "code",
        "outputId": "e267af5d-59e5-4c0c-a6f8-f791d43e1151",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 193
        }
      },
      "source": [
        "# instantiate pre-built estimator\n",
        "regressor = tf.estimator.LinearRegressor(\n",
        "    feature_columns=feature_columns)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Using default config.\n",
            "WARNING:tensorflow:Using temporary folder as model directory: /tmp/tmpwmc9p8q4\n",
            "INFO:tensorflow:Using config: {'_model_dir': '/tmp/tmpwmc9p8q4', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
            "graph_options {\n",
            "  rewrite_options {\n",
            "    meta_optimizer_iterations: ONE\n",
            "  }\n",
            "}\n",
            ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': ClusterSpec({}), '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "slx9_W5uYPWU",
        "colab_type": "text"
      },
      "source": [
        "# step 4: apply train, evaluate, predict methods of the evaluator"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XkPEm9iVYRc-",
        "colab_type": "code",
        "outputId": "486494ca-3eac-4ad4-fd2b-32d20750565b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 644
        }
      },
      "source": [
        "# train the estimator\n",
        "regressor.train(\n",
        "    input_fn=lambda: input_fn(df_train, shuffle=True, batch_size=32),\n",
        "    steps=2000) \n",
        "\n",
        "# steps define how many epochs to loop through the dataset\n",
        "# here, define 100 epochs for training"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/resource_variable_ops.py:1635: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "If using Keras pass *_constraint arguments to layers.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/training_util.py:236: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\n",
            "INFO:tensorflow:Calling model_fn.\n",
            "WARNING:tensorflow:Layer linear/linear_model is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
            "\n",
            "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
            "\n",
            "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/feature_column/feature_column_v2.py:518: Layer.add_variable (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `layer.add_weight` method instead.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/feature_column/feature_column_v2.py:4267: IndicatorColumn._variable_shape (from tensorflow.python.feature_column.feature_column_v2) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "The old _FeatureColumn APIs are being deprecated. Please use the new FeatureColumn APIs instead.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/feature_column/feature_column_v2.py:4322: VocabularyListCategoricalColumn._num_buckets (from tensorflow.python.feature_column.feature_column_v2) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "The old _FeatureColumn APIs are being deprecated. Please use the new FeatureColumn APIs instead.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/optimizer_v2/ftrl.py:143: calling Constant.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "INFO:tensorflow:Create CheckpointSaverHook.\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "INFO:tensorflow:Saving checkpoints for 0 into /tmp/tmpwmc9p8q4/model.ckpt.\n",
            "INFO:tensorflow:loss = 144.53561, step = 0\n",
            "INFO:tensorflow:Saving checkpoints for 37 into /tmp/tmpwmc9p8q4/model.ckpt.\n",
            "INFO:tensorflow:Loss for final step: 0.33021903.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow_estimator.python.estimator.canned.linear.LinearRegressorV2 at 0x7fcf20150128>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1JxpEQfgYWNH",
        "colab_type": "code",
        "outputId": "93e22ed3-3c94-45d1-ef61-52a10f106242",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 436
        }
      },
      "source": [
        "# evaluate the estimator\n",
        "eval_result = regressor.evaluate(\n",
        "    input_fn=lambda: input_fn(df_validation, shuffle=False, batch_size=32))\n",
        "\n",
        "print(pd.Series(eval_result))\n",
        "# here, only one epoch for estimator evaluation"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Calling model_fn.\n",
            "WARNING:tensorflow:Layer linear/linear_model is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
            "\n",
            "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
            "\n",
            "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
            "\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "INFO:tensorflow:Starting evaluation at 2020-02-11T13:37:05Z\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Restoring parameters from /tmp/tmpwmc9p8q4/model.ckpt-37\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "INFO:tensorflow:Inference Time : 1.75418s\n",
            "INFO:tensorflow:Finished evaluation at 2020-02-11-13:37:07\n",
            "INFO:tensorflow:Saving dict for global step 37: average_loss = 0.21613409, global_step = 37, label/mean = 12.0290985, loss = 0.21110424, prediction/mean = 12.024432\n",
            "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 37: /tmp/tmpwmc9p8q4/model.ckpt-37\n",
            "average_loss        0.216134\n",
            "label/mean         12.029099\n",
            "loss                0.211104\n",
            "prediction/mean    12.024432\n",
            "global_step        37.000000\n",
            "dtype: float64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g11XYvLrH0Ig",
        "colab_type": "text"
      },
      "source": [
        "# generate prediction output"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cXwknmFoCNZq",
        "colab_type": "code",
        "outputId": "ed0c0683-c1f0-4c39-96cb-b142a52da08e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 245
        }
      },
      "source": [
        "submission = []\n",
        "\n",
        "for ele in regressor.predict(input_fn=lambda: input_fn(df_test, shuffle=False, batch_size=32)):\n",
        "  submission.append(np.expm1(ele['predictions']))\n",
        "\n",
        "df = pd.DataFrame(columns = ['Id', 'SalePrice'])\n",
        "df['Id'] = df_test['Id']\n",
        "df['SalePrice'] = submission\n",
        "\n",
        "df.to_csv(r\"submission.csv\")"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Calling model_fn.\n",
            "WARNING:tensorflow:Layer linear/linear_model is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
            "\n",
            "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
            "\n",
            "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
            "\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Restoring parameters from /tmp/tmpwmc9p8q4/model.ckpt-37\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4vTUK_Q05fwl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}